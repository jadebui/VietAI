{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aubCX1FWU6R"
   },
   "source": [
    "## Assignment 2: Deep Neural Network \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TJT9yeVWU6R"
   },
   "source": [
    "### Giới thiệu\n",
    "\n",
    "Để có thể hoàn tất bài tập này, các bạn cần nắm rõ những kiến thức sau:\n",
    "\n",
    "    - Neural Networks - Fully connected networks là gì, nguyên tắc hoạt động ra sao.\n",
    "\t- Giải thuật Feedforward và BackPropagation trong bài toán NN.\n",
    "\t- Giải thuật gradient descent - Batch and Mini-batch.\n",
    "\t- Regularization để tránh overfitting trong NN.\n",
    "\n",
    "Các bạn có thể tham khảo lại bài giảng của lớp để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng dạy nếu có thắc mắc. \n",
    "\n",
    "Trong bài tập này các bạn sẽ sử dụng Neural Networks để giải quyết 2 bài toán:\n",
    "\n",
    "\t- Bài 1: phân loại dữ liệu BAT, gồm 3 lớp.\n",
    "![Dữ liệu 3 class BAT](https://i.imgur.com/d1Pd1XT.png)\n",
    "\t- Bài 2: phân loại tập fashion MNIST, gồm 10 lớp.\n",
    "![Dữ liệu Fashion MNIST](https://i.imgur.com/O9dqdId.png)\n",
    "Yêu cầu dành cho các bạn trong là giải quyết hai bài trên bằng Numpy và TensorFlow.\n",
    "\n",
    "Mục tiêu của bài tập lần này là hiện thực Neural Networks mạng Fully Connected một cách cơ bản trên Numpy và Tensorflow. Một mạng cơ bản sẽ gồm nhiều hidden layers và một lớp softmax tại layer cuối cùng phù hợp cho việc phân loại dữ liệu. \n",
    "\n",
    "![Mạng neural network. Nguồn: graphicsminer.com/neuralnetwork](https://i.imgur.com/K3Yvt20.png)\n",
    "\n",
    "Khi thiết kế một mạng cơ bản thì người dùng có thể quyết định số input feature cho tầng input. Số output sẽ là số lớp mà người đó muốn phân loại. Ví dụ như bài toán fashion MNIST thì số feature đầu vào chính bằng số pixel của mỗi ảnh, số nút đầu ra sẽ bằng số lớp cần phân loại (10). Đối với số lượng hidden layer và số lượng nodes tương ứng, ta có thể tùy chọn.\n",
    "\n",
    "Một chú ý rất quan trọng là số nodes đầu ra của layer trước sẽ là số inputs đầu vào của layers sau đó.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoOck2DCWU6S"
   },
   "source": [
    "## I/ Thực hiện Deep Neural Network với Numpy\n",
    "### Những công việc bạn phải thực hiện \n",
    "\n",
    "1. Các hàm activation `sigmoid`, `tanh`, `relu`, `softmax` và đạo hàm của nó `sigmoid_grad`, `tanh_grad`, `relu_grad`.\n",
    "2. Hàm `forward` và `backward` ở class `HiddenLayer`\n",
    "```python\n",
    "    class HiddenLayer:\n",
    "    \n",
    "        def forward(self, X):\n",
    "            ...\n",
    "    \n",
    "        def backward(self, X, delta_prev):\n",
    "            ...\n",
    "```\n",
    "3. Hàm `forward`, `backward`, `compute_loss` ở class `NeuralNetwork`\n",
    "```python\n",
    "    class NeuralNetwork:\n",
    "        \n",
    "        def forward(self, X):\n",
    "            ...\n",
    "            \n",
    "        def backward(self, X, Y, layers):\n",
    "            ...\n",
    "            \n",
    "        def compute_loss(self, Y, Y_hat):\n",
    "            ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sR1nh0HmWU6S"
   },
   "source": [
    "### Ký hiệu:\n",
    "\n",
    "- $L$: số layers trong mạng neural network. \n",
    "- $l = 0,1,..,L$ với $0$ là layer input và $L$ layer output.\n",
    "- $n^{[l]}$ là số neurons tại layer $l$\n",
    "- $l-1$: layer trước theo chiều forward của $l$.\n",
    "- $l+1$: layer trước theo chiều backward của $l$.\n",
    "- $\\sigma'(x)$: đạo hàm hàm activation theo x (general case cho cả đạo hàm sigmoid, tanh, relu).\n",
    "- $Z^{[l]}$: linear function values tại layer $l$.\n",
    "- $A^{[l]}$: activation function values tại layer $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaHjKk8NWU6T"
   },
   "source": [
    "### Import các thư viện cần thiết cho bài assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcPK2dtVMQ75"
   },
   "source": [
    "**Chú ý:** Nếu bạn chạy trên Google Colab thì các thư viện này đã được tích hợp sẵn. Nếu bạn chạy trên máy cá nhân, bạn cần install các thư viện *numpy*, *matplotlib*, *googledrivedownloader*, *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfJTsubxWU6U"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3py26bW_WU6W"
   },
   "source": [
    "### Download files dữ liệu về từ google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "yrtam5dxWU6W",
    "outputId": "208ded1b-31fd-4f99-94bc-1f274c117bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1EXSdvCLlcXvl1Gi6sNSJCu6psICoLNNc into /media/thieu/captain/vietAI/assignment2/solution/Assignment2.zip... Done.\n",
      "Unzipping...Done.\n",
      "2_SolutionDeepNeuralNetwork.ipynb  data  test  utils\n"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD DATA\n",
    "gdd.download_file_from_google_drive(file_id='1EXSdvCLlcXvl1Gi6sNSJCu6psICoLNNc', \n",
    "                                    dest_path=os.path.join(os.getcwd(), 'Assignment2.zip'), unzip=True)\n",
    "\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    !move \"./Assignment2/data\" \".\"\n",
    "    !move \"./Assignment2/test\" \".\"\n",
    "    !move \"./Assignment2/utils\" \".\"\n",
    "    !del \"Assignment2.zip\"\n",
    "    !rd /s /q \"Assignment2\" \"__MACOSX\"\n",
    "    !dir\n",
    "else:\n",
    "    !mv Assignment2/* .\n",
    "    !rm Assignment2.zip\n",
    "    !rm -rf Assignment2 __MACOSX\n",
    "    # SHOW THE ITEMS OF CURRENT DIRRECTORY\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9-jw8LMP7tn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM2C8VBIZpJ-"
   },
   "source": [
    "### Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FW8Bh97nZttw"
   },
   "outputs": [],
   "source": [
    "from utils.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JFz8ZfBWU6Y"
   },
   "source": [
    "### Các hàm activation\n",
    "\n",
    "$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "$$tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$\n",
    "\n",
    "$$relu(x) = \\begin{cases} x, & \\mbox{if } x > 0 \\\\ 0, & \\mbox{if } x <= 0 \\end{cases}$$\n",
    "\n",
    "$$sigmoid'(x) = sigmoid(x)(1 - sigmoid(x)) $$\n",
    "\n",
    "$$tanh'(x) = 1 - tanh^2(x)$$\n",
    "\n",
    "$$relu'(x) = \\begin{cases} 1, & \\mbox{if } x > 0 \\\\ 0, & \\mbox{if } x <= 0 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0XRJ8Pkqfrk"
   },
   "source": [
    "#### \\[TODO 1\\] Các hàm activation\n",
    "Định nghĩa các hàm activation ở cell bên dưới. (1đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaRr075NWU6Y"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid function. Output = 1 / (1 + exp(-1)).\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    x = 1/(1+np.exp(-x))\n",
    "    #### END CODE HERE ####\n",
    "    return x\n",
    "\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    \"\"\"\n",
    "    Compute gradient of sigmoid.\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "    \n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    da = (sigmoid(x))*(1-sigmoid(x))\n",
    "    #### END CODE HERE ####\n",
    "    return da\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    Rectified linear unit function. Output = max(0,x).\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "    \n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    x = np.maximum(0,x)\n",
    "    #### END CODE HERE ####\n",
    "    return x\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "    \"\"\"\n",
    "    Compute gradient of ReLU.\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "    \n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    da = relu(x)\n",
    "    da[da > 0] = 1\n",
    "    #### END CODE HERE ####\n",
    "    return da\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\"\n",
    "    Tanh function.\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "   \n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    x = (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "    #### END CODE HERE ####\n",
    "    return x\n",
    "\n",
    "\n",
    "def tanh_grad(x):\n",
    "    \"\"\"\n",
    "    Compute gradient for tanh.\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "\n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    da =  1 - tanh(x)**2\n",
    "    #### END CODE HERE ####\n",
    "    return da\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Stable softmax function.\n",
    "    :param x: input\n",
    "    \"\"\"\n",
    "    #### [TODO 1] START CODE HERE #### \n",
    "    exp_scores = np.exp(x - np.max(x, axis = 1, keepdims = True))\n",
    "    probs = exp_scores/np.sum(exp_scores, axis = 1, keepdims = True)\n",
    "    #### END CODE HERE ####\n",
    "    return probs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xt_ai6WdWU6a"
   },
   "source": [
    "#### Kiểm tra lại lại các hàm activation đã cài đặt\n",
    "\n",
    "Bạn có thể kiểm tra cái hàm bạn đã cài đặt bằng đoạn code bên dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E2lOqDOIWU6a",
    "outputId": "7d704fc3-3d9c-43c1-ab90-4562cf2284bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PASS!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "np.random.seed(2019)\n",
    "func_test = [\"sigmoid\", \"relu\", \"tanh\", \"sigmoid_grad\", \"relu_grad\", \"tanh_grad\", \"softmax\"]\n",
    "test_activation = dict()\n",
    "results = []\n",
    "with open(\"test/activation.pkl\", \"rb\") as f:\n",
    "    test_activation = pickle.load(f)\n",
    "\n",
    "test_x = test_activation[\"test_x\"]\n",
    "sample = test_activation[\"sample\"]\n",
    "\n",
    "for i, func_str in enumerate(func_test):\n",
    "    func = eval(func_str)\n",
    "    sample.append(func(test_x))\n",
    "    if not np.allclose(func(test_x), sample[i]):\n",
    "        results.append(func_str)\n",
    "\n",
    "if len(results) == 0:\n",
    "    print(\"Test PASS!\")\n",
    "else:\n",
    "    print(\"Test FAILED: \" + \", \".join(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAXiX8q6WU6d"
   },
   "source": [
    "### Class `HiddenLayer` \n",
    "\n",
    "#### Hướng dẫn:\n",
    "\n",
    "1. Hàm `forward`:\n",
    "- Hàm nhận vào tham số input $X$ (là output của hidden layer trước theo chiều forward, layer $l-1$).\n",
    "- Tính linear transformation của $X$ ($A^{[l-1]}$): $Z^{[l]} = XW$.\n",
    "- Sau đó tính nonlinear transformation: $A^{[l]} = \\sigma(Z^{[l]})$ với $\\sigma$ là hàm activation.\n",
    "    \n",
    "2. Hàm `backward`:\n",
    "- Hàm nhận vào 2 tham số input `X`(là output của hidden layer trước đó theo chiều forward) với `delta_prev` (delta trước đó theo chiều backward).\n",
    "- Tính delta tại layer $l$: \n",
    "    \n",
    "    $$\\delta^{[l]} = \\frac{\\partial J}{\\partial A^{[l]}}\\frac{\\partial A^{[l]}}{\\partial Z^{[l]}} =  \\delta^{[l+1]} * \\sigma'(Z^{[l]})$$ \n",
    "\n",
    "Chú ý: $*$ operation là element-wise multiplication.\n",
    "- Tính W_grad (without regularization): $\\nabla W^{[l]} = (A^{[l-1]})^T\\delta^{[l]} $\n",
    "- With regularization:  $\\nabla W^{[l]} = (A^{[l-1]})^T\\delta^{[l]} + \\frac{\\lambda}{m} W^{[l]}$ với $\\lambda$ là hệ số regularization (hyperparameter mình sẽ chọn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvz4a9OVvWbP"
   },
   "source": [
    "#### \\[TODO 2\\] Hàm `forward`\n",
    "Định nghĩa hàm `forward` trong class `HiddenLayer` (1đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k36DABvNvmXW"
   },
   "source": [
    "#### \\[TODO 3\\] Hàm `backward` \n",
    "Định nghĩa hàm `backward` trong class `HiddenLayer` (2đ)\n",
    "  + Tính W_grad (without regularization) (1đ)\n",
    "  + Tính W_grad (with L2 regularization) (1đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcKvwjzIWU6d"
   },
   "outputs": [],
   "source": [
    "class HiddenLayer:\n",
    "    \"\"\"\n",
    "    Abstract hidden layer use in Neural Network.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_neurons, activation, reg = 0):\n",
    "        \"\"\"\n",
    "        Constructor for abstract hidden layer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_neurons: (integer) specify number of neurons in this layer.\n",
    "        activation: (string) indicating which activation function to be used.  \n",
    "                        the string must be in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"]\n",
    "        reg: (float) regularization coefficient to help with overfitting.\n",
    "        \"\"\"\n",
    "        assert activation in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"], \"Activation must be in [sigmoid, relu, tanh, softmax]\"\n",
    "        self.num_neurons = num_neurons\n",
    "        self.W = None \n",
    "        self.activation = activation\n",
    "        self.reg = reg\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute nonlinear function of input X.\n",
    "            X -> LINEAR -> ACTIVATION.\n",
    "            \n",
    "        `activation_function` variable below is equal to this piece of code:\n",
    "        \n",
    "            if (self.activation == 'sigmoid'):\n",
    "                activation_function = sigmoid\n",
    "            elif (self.activation == 'relu'):\n",
    "                activation_function = reLU\n",
    "            elif (self.activation == 'tanh'):\n",
    "                activation_function = tanh\n",
    "            elif (self.activation == 'softmax'):\n",
    "                activation_function = softmax\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: output of the previous layer (input for the current layer).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A: output of the current layer.\n",
    "        \"\"\"\n",
    "        if self.W is None:\n",
    "            W_shape = (X.shape[1], self.num_neurons)\n",
    "            self.W = np.random.normal(0, np.sqrt(2/(X.shape[1]+self.num_neurons)), W_shape)\n",
    "        \n",
    "        activation_function = eval(self.activation) # this returns function variable\n",
    "        \n",
    "        #### [TODO 2] START CODE HERE ####\n",
    "        self.Z = np.dot(X, self.W)\n",
    "        A = activation_function(self.Z) # use `activation_function` function above apply to `Z`\n",
    "        #### END CODE HERE ####\n",
    "        return A\n",
    "\n",
    "    def backward(self, X, delta_prev):\n",
    "        \"\"\"\n",
    "        Compute gradient w.r.t X and W at the current layer.\n",
    "            X <- LINEAR <- ACTIVATION.\n",
    "            W <- LINEAR <- ACTIVATION.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: output of the previous layer (input for the current layer).\n",
    "        delta_prev: delta dot product with W computed from the next layer (in feedforward direction) \n",
    "                                or previous layer (in backpropagation direction)\n",
    "        \"\"\"\n",
    "        activation_grad_function = eval(self.activation + \"_grad\")\n",
    "        z = self.Z\n",
    "\n",
    "        #### [TODO 3] START CODE HERE ####\n",
    "        delta = delta_prev * activation_grad_function(z)\n",
    "        W_grad = X.T.dot(delta)\n",
    "        #### END CODE HERE ####\n",
    "\n",
    "        #### [TODO 3] START CODE HERE ####\n",
    "        W_grad += self.reg*self.W/X.shape[0]\n",
    "        #### END CODE HERE ####\n",
    "        \n",
    "        return W_grad, delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxBEnVcqWU6f"
   },
   "source": [
    "#### Kiểm tra class `HiddenLayer` được cài đặt\n",
    "\n",
    "Bạn có thể kiểm tra class `HiddenLayer` bạn đã cài đặt bằng cách chạy cell bên dưới:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Udcfv7EbaMsI",
    "outputId": "055dea69-4cb7-4589-b37f-f58179378caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST HiddenLayer WITHOUT REGULARIZATION\n",
      "Test PASS!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2019)\n",
    "case_1 = HiddenLayer(10, \"sigmoid\", reg=0)\n",
    "case_2 = HiddenLayer(14, \"tanh\", reg=0)\n",
    "case_3 = HiddenLayer(17, \"relu\", reg=0)\n",
    "\n",
    "case_mapping = {0: \"(foward)\", 1: \"(backward W_grad)\", 2: \"(backward delta)\"}\n",
    "\n",
    "with open(\"test/hidden.pkl\", \"rb\") as f:\n",
    "    test_hidden = pickle.load(f)\n",
    "\n",
    "test_x = test_hidden[\"test_x\"]\n",
    "sample = test_hidden[\"sample\"]\n",
    "test_delta = test_hidden[\"test_delta\"]\n",
    "results = []\n",
    "for ind, cl_str in enumerate([\"case_1\", \"case_2\", \"case_3\"]):\n",
    "    hidden_layer = eval(cl_str)\n",
    "    case = (hidden_layer.forward(test_x), ) + hidden_layer.backward(test_x, test_delta[ind])\n",
    "    for i in range(3):\n",
    "        if not np.allclose(sample[ind][i], case[i]):\n",
    "            results.append(cl_str + case_mapping[i])\n",
    "\n",
    "print(\"TEST HiddenLayer WITHOUT REGULARIZATION\")\n",
    "if len(results) == 0:\n",
    "    print(\"Test PASS!\")\n",
    "else:\n",
    "    print(\"Test FAILED: \" + \", \".join(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfYPF3NIaMsK"
   },
   "source": [
    "Các bạn nên chắc chắn rằng mình đã pass hết các test cases để làm tiếp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4londbBaMsL"
   },
   "source": [
    "#### Đoạn code kiểm tra Hidden Layer với Regularization\n",
    "\n",
    "Các bạn có thể skip phần test case này nếu chưa làm với Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XYQnbqK-aMsL",
    "outputId": "8acda840-fe56-46c4-8eb1-6e847845e22a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST HiddenLayer WITH REGULARIZATION\n",
      "Test PASS!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2019)\n",
    "case_1 = HiddenLayer(10, \"sigmoid\", reg=0.9)\n",
    "case_2 = HiddenLayer(14, \"tanh\", reg=0.9)\n",
    "case_3 = HiddenLayer(17, \"relu\", reg=0.9)\n",
    "\n",
    "case_mapping = {0: \"(foward)\", 1: \"(backward W_grad)\", 2: \"(backward delta)\"}\n",
    "\n",
    "with open(\"test/hidden_reg.pkl\", \"rb\") as f:\n",
    "    test_hidden = pickle.load(f)\n",
    "\n",
    "test_x = test_hidden[\"test_x\"]\n",
    "sample = test_hidden[\"sample\"]\n",
    "test_delta = test_hidden[\"test_delta\"]\n",
    "results = []\n",
    "for ind, cl_str in enumerate([\"case_1\", \"case_2\", \"case_3\"]):\n",
    "    hidden_layer = eval(cl_str)\n",
    "    case = (hidden_layer.forward(test_x), ) + hidden_layer.backward(test_x, test_delta[ind])\n",
    "    for i in range(3):\n",
    "        if not np.allclose(sample[ind][i], case[i]):\n",
    "            results.append(cl_str + case_mapping[i])\n",
    "\n",
    "print(\"TEST HiddenLayer WITH REGULARIZATION\")\n",
    "if len(results) == 0:\n",
    "    print(\"Test PASS!\")\n",
    "else:\n",
    "    print(\"Test FAILED: \" + \", \".join(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBM_ewnfWU6h"
   },
   "source": [
    "### Class `NeuralNetwork`\n",
    "\n",
    "#### Hướng dẫn:\n",
    "\n",
    "1. Hàm `forward`:\n",
    "- Sử dụng hàm `forward` class `HiddenLayer`. Output của layer này [$l$] sẽ là input của layer sau [$l+1$]. Thêm output của layer [$l$] vào list `all_X` \n",
    "\n",
    "\n",
    "2. Hàm `compute_loss`:\n",
    "- Cross-entropy, không regularization: $$J = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^C y_{ik}\\log(a_{ik}^{[L]})$$\n",
    "- Cross-entropy, L2 regularization: $$J = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^C y_{ik}\\log(a_{ik}^{[L]}) + \\frac{\\lambda}{2m}\\sum_{l=1}^L\\|\\mathbf{W}^{[l]} \\|_2^2$$\n",
    "    \n",
    "    \n",
    "3. Hàm `backward`:\n",
    "\n",
    "- Tính `delta_last` $\\delta^{[L]} $ và `grad_last` $\\nabla W^{[L]}$ theo hàm softmax (để ý superscript [L]): \n",
    "    \n",
    "    $$\\delta^{[L]} = \\frac{\\partial J}{\\partial \\mathbf{A}^{[L]}}\\frac{\\partial \\mathbf{A}^{[L]}}{\\partial \\mathbf{Z}^{[L]}} = \\frac{1}{m} (\\mathbf{A}^{[L]} - \\mathbf{Y})$$\n",
    "\n",
    "    - **Without regularization:**\n",
    "        \n",
    "        $$\\nabla W^{[L]} = \\frac{\\partial J}{\\partial \\mathbf{A}^{[L]}}\\frac{\\partial \\mathbf{A}^{[L]}}{\\partial \\mathbf{Z}^{[L]}}\\frac{\\partial \\mathbf{Z}^{[L]}}{\\partial \\mathbf{W}^{[L]}} = \\delta^{[L]} \\frac{\\partial \\mathbf{Z}^{[L]}}{\\partial \\mathbf{W}^{[L]}} = (\\mathbf{A}^{[L-1]})^T \\delta^{[L]} $$\n",
    "\n",
    "    - **With L2 regularization:**\n",
    "\n",
    "        $$\\nabla \\mathbf{W}^{[L]} = (\\mathbf{A}^{[L-1]})^T \\delta^{[L]} + \\frac{\\lambda}{m} W^{[l]}$$\n",
    "\n",
    "- Tính `delta_prev` $\\delta^{[l]}$ và `grad_W` $\\nabla \\mathbf{W}^{[l]}$ ở các tầng ở giữa:\n",
    "    \n",
    "    $$\\delta^{[l]} = \\left(\\delta^{[l+1]}(\\mathbf{W}^{[l+1]})^T\\right) * \\sigma'(\\mathbf{Z^{[l]}})$$\n",
    "    \n",
    "    - **Without regularization**\n",
    "        \n",
    "        $$\\nabla \\mathbf{W}^{[l]} = (\\mathbf{A}^{[l-1]})^T \\delta^{[l]}$$\n",
    "\n",
    "    - **With L2 regularization**\n",
    "\n",
    "        $$\\nabla \\mathbf{W}^{[l]} = (\\mathbf{A}^{[l-1]})^T \\delta^{[l]} + \\frac{\\lambda}{m} W^{[l]}$$\n",
    "        \n",
    "Mục đích tính `delta` để tính gradient của `W` ở các tầng trước theo chiều forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9PVWSh6wxVN"
   },
   "source": [
    "#### \\[TODO 4\\] Hàm `forward`\n",
    "Định nghĩa hàm `forward` trong class `NeuralNetwork` (0.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYuwmMEFw1hr"
   },
   "source": [
    "#### \\[TODO 5\\] Hàm `compute_loss`\n",
    "Định nghĩa hàm `compute_loss` trong class `NeuralNetwork` (1.5đ)\n",
    "  + Loss without regularization (1đ)\n",
    "  + Loss of L2 regularization (0.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xo0blEFKw5Pg"
   },
   "source": [
    "#### \\[TODO 6\\] Hàm `compute_delta_grad_last`\n",
    "Định nghĩa hàm `compute_delta_grad_last` trong class `NeuralNetwork` (1đ)\n",
    "  + Without regularization (0.5đ)\n",
    "  + With L2 regularization (0.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNjzFiDUw8kI"
   },
   "source": [
    "#### [TODO 7] Hàm `backward`\n",
    "Định nghĩa hàm `backward` trong class `NeuralNetwork` (1đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dxrf3fgWxAVa"
   },
   "source": [
    "#### \\[TODO 8\\] Hàm `update_weight_momentum`\n",
    "Định nghĩa hàm `update_weight_momentum` trong class `NeuralNetwork`. (1đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfwaEowzWU6h"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, learning_rate, num_class=2, reg = 1e-5):\n",
    "        self.layers = []\n",
    "        self.reg = reg\n",
    "        self.num_class = num_class\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def add_layer(self, num_neurons, activation):\n",
    "        \"\"\"\n",
    "        Function to add a hidden layer to neural network.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_neurons: hyperparameter that specify nuber of neurons new hidden layer have/\n",
    "        activation: string, indicating which activation function to be used\n",
    "        \"\"\"\n",
    "        assert activation in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"], \"Activation must be in [sigmoid, relu, tanh, softmax]\"\n",
    "        self.layers.append(HiddenLayer(num_neurons, activation, self.reg))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Do forward propagation in the neural network\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: raw input X.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        all_X: list of all X computed at each layer. \n",
    "        \"\"\"\n",
    "        all_X = [X]\n",
    "        #### [TODO 4] START CODE HERE ####\n",
    "        for layer in self.layers:\n",
    "            all_X.append(layer.forward(all_X[-1]))\n",
    "        #### END CODE HERE ####\n",
    "        return all_X\n",
    "    \n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        \"\"\"\n",
    "        Compute the average cross entropy loss using Y (label) and Y_hat (predicted class)\n",
    "                    and plus with regularization loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n",
    "                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n",
    "                                      [0, 1, 0],\n",
    "                                      [0, 0, 1],\n",
    "                                      [0, 1, 0]]\n",
    "        Y_hat: the propabilities of classes (output of softmax).\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        \"\"\"\n",
    "        #estimating cross entropy loss from y_hat and y\n",
    "        #### [TODO 5] START CODE HERE ####\n",
    "        correct_log_probs = Y*np.log(Y_hat)\n",
    "        data_loss = np.mean(-np.sum(correct_log_probs, axis=1), axis=0)\n",
    "        #### END CODE HERE ####\n",
    "\n",
    "        #estimating regularization loss from all layers\n",
    "        reg_loss = 0.0\n",
    "        #### [TODO 5] START CODE HERE ####\n",
    "        # compute reg_loss\n",
    "        for i in range(len(self.layers)):\n",
    "            reg_loss += 0.5*self.reg*np.sum(self.layers[i].W**2)\n",
    "        #### END CODE HERE ####\n",
    "\n",
    "        data_loss += reg_loss/Y.shape[0]\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def compute_delta_grad_last(self, Y, all_X):\n",
    "        \"\"\"\n",
    "        Special formula to compute delta last and gradient last.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n",
    "                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n",
    "                                      [0, 1, 0],\n",
    "                                      [0, 0, 1],\n",
    "                                      [0, 1, 0]]\n",
    "                                      \n",
    "        all_X: raw input data and activation output from every layer\n",
    "        \"\"\"\n",
    "        n = Y.shape[0]\n",
    "        #### [TODO 6] START CODE HERE ####\n",
    "        delta_last = (all_X[-1] - Y)/n\n",
    "        grad_last = all_X[-2].T.dot(delta_last) + self.reg*self.layers[-1].W/n\n",
    "        #### END CODE HERE ####\n",
    "        return delta_last, grad_last\n",
    "\n",
    "    def backward(self, Y, all_X):\n",
    "        \"\"\"\n",
    "        Backpropagation algorithm to compute gradient at each layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n",
    "                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n",
    "                                      [0, 1, 0],\n",
    "                                      [0, 0, 1],\n",
    "                                      [0, 1, 0]]\n",
    "        all_X: raw input data and activation output from every layer\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        grad_list: list of gradients we've just computed at each layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute delta_last factor from the output\n",
    "        delta_prev, grad_last = self.compute_delta_grad_last(Y, all_X)\n",
    "\n",
    "        grad_list = [grad_last]\n",
    "\n",
    "        for i in range(len(self.layers) - 1)[::-1]:\n",
    "            prev_layer = self.layers[i+1] # previous layer as backward direction\n",
    "            layer = self.layers[i]\n",
    "            X = all_X[i]\n",
    "            #### [TODO 7] START CODE HERE ####\n",
    "            delta_prev = delta_prev.dot(prev_layer.W.T)\n",
    "            grad_W, delta_prev = layer.backward(X, delta_prev)\n",
    "            #### END CODE HERE ####\n",
    "            grad_list.append(grad_W)\n",
    "\n",
    "        grad_list = grad_list[::-1]\n",
    "        return grad_list\n",
    "\n",
    "    def update_weight(self, grad_list):\n",
    "        \"\"\"\n",
    "        Update W by gradient descent using the computed gradient.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        grad_list: (list) list of gradients from all layers that computed from backward function above\n",
    "        learning_rate: (float) learning rate for gradient descent.\n",
    "        \"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            grad = grad_list[i]\n",
    "            layer.W = layer.W - self.learning_rate * grad\n",
    "    \n",
    "    def update_weight_momentum(self, grad_list, momentum_rate):\n",
    "        \"\"\"\n",
    "        Update W using gradient descent with momentum\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grad_list: (list) list of gradients from all layers that computed from backward function above\n",
    "        learning_rate: (float) learning rate.\n",
    "        momentum_rate: (float) momentum rate.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"momentum\"):\n",
    "            self.momentum = [np.zeros_like(grad) for grad in grad_list]\n",
    "           \n",
    "        #### [TODO 8] START CODE HERE ####\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            self.momentum[i] = self.momentum[i]*momentum_rate + self.learning_rate*grad_list[i]\n",
    "            layer.W = layer.W - self.momentum[i]\n",
    "        #### END CODE HERE ####\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        Y_hat = self.forward(X_test)[-1]\n",
    "        return np.argmax(Y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Bgw-Oh_ybyY"
   },
   "source": [
    "### Training\n",
    "\n",
    "Sau khi định nghĩa các classes HiddenLayer và NeuralNetwork, chúng ta thực hiện huấn luyện (training) mô hình. Trong bài tập này, 2 kỹ thuật training được giới thiệu:\n",
    "  \n",
    "  + Batch train\n",
    "  + Mini-batch train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tbgwx4t_zG-F"
   },
   "source": [
    "#### Batch train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2l8z9nmWU6j"
   },
   "source": [
    "Định nghĩa hàm `batch_train` để  train trên toàn dữ liệu. Có nghĩa là weights `W` trên mạng neural network sẽ được update trên toàn điểm dữ liệu, thay vì ở mỗi batch điểm dữ liệu như là `mini_batch_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgryBOGbWU6j"
   },
   "outputs": [],
   "source": [
    " def batch_train(X_train, Y_train, epochs, neural_network, bat=False):\n",
    "    \"\"\"\n",
    "    Using batch train.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: training data X.\n",
    "    Y_train: training data Y.\n",
    "    epochs: number of iterations that we should use to train.\n",
    "    neural_network: NeuralNetwork object instance above.\n",
    "    \"\"\"\n",
    "    all_loss = []\n",
    "    display_step = 100 if bat else 10\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        all_X = neural_network.forward(X_train)\n",
    "        loss = neural_network.compute_loss(Y_train, all_X[-1])\n",
    "        grad_list = neural_network.backward(Y_train, all_X)\n",
    "        neural_network.update_weight(grad_list)\n",
    "        \n",
    "        all_loss.append(loss)\n",
    "        \n",
    "        if (e+1) % display_step == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            \n",
    "            if bat:\n",
    "                y_hat = neural_network.forward(X_train)[-1]\n",
    "                visualize_point(X_train, np.argmax(Y_train,axis=1), y_hat)\n",
    "            plot_loss(all_loss, title=\"Loss epoch %s: %.4f\" % (e+1, loss), color=2)\n",
    "            plt.show()\n",
    "            plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUd2QWbYWU6l"
   },
   "source": [
    "#### \\[TODO 9\\] Mini-batch train\n",
    "Định nghĩa hàm `mini_batch_train` (2đ)\n",
    "\n",
    "**Pseudocode:**\n",
    "\n",
    "```\n",
    "-> For each epoch do:\n",
    "    -> Shuffle data\n",
    "    -> Set initial loss at that epoch equal to 0\n",
    "    -> Calculate number of batches based on batch size and total number of data points\n",
    "    -> For each batch do:\n",
    "        -> all_X := nn.forward() at that batch, Y_hat is equal all_X[-1]\n",
    "        -> compute loss at that batch\n",
    "        -> initial loss += computed loss at that batch\n",
    "        -> grad_list := nn.backward()\n",
    "        -> update weights.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mxAl4-lWU6m"
   },
   "outputs": [],
   "source": [
    " def minibatch_train(X_train, Y_train, epochs, batch_size, num_class, neural_network):\n",
    "    \"\"\"\n",
    "    Using batch train.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: training data X.\n",
    "    Y_train: training data Y.\n",
    "    epochs: number of iterations that we should use to train.\n",
    "    batch_size: number of batch at each update.\n",
    "    neural_network: NeuralNetwork object instance above.\n",
    "    \n",
    "    \"\"\"\n",
    "    #### [TODO 9] START CODE HERE ####\n",
    "    data = np.concatenate((X_train, Y_train), axis=1)\n",
    "    n = data.shape[0]\n",
    "    for e in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        X_train, Y_train = data[:, :-num_class], data[:, -num_class:]\n",
    "        num_batches = n // batch_size if n % batch_size == 0 else n // batch_size + 1\n",
    "        all_loss = 0.0\n",
    "        for b in range(num_batches):\n",
    "            all_X = neural_network.forward(X_train[b:b+batch_size])\n",
    "            loss = neural_network.compute_loss(Y_train[b:b+batch_size], all_X[-1])\n",
    "            grad_list = neural_network.backward(Y_train[b:b+batch_size], all_X)\n",
    "            neural_network.update_weight(grad_list)\n",
    "            all_loss += loss\n",
    "        print(\"Loss epoch %s: %.4f\" % (e, all_loss/num_batches))\n",
    "    #### END CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qwKm1md29Do"
   },
   "source": [
    "### Bat classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulg41hJv3BVa"
   },
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DpNCieI3FHt"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "LEARNING_RATE = 0.02\n",
    "REG= 1e-5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pB01QyBYWU6o"
   },
   "outputs": [],
   "source": [
    "def bat_classification(use_batch_train=True):\n",
    "    # Load data from file\n",
    "    # Make sure that bat.dat is in data/\n",
    "    train_X, train_Y, test_X, test_Y = get_bat_data()\n",
    "    train_X, _, test_X = normalize(train_X, train_X, test_X)    \n",
    "\n",
    "    test_Y  = test_Y.flatten()\n",
    "    train_Y = train_Y.flatten()\n",
    "    num_class = (np.unique(train_Y)).shape[0]\n",
    "\n",
    "    # Pad 1 as the third feature of train_x and test_x\n",
    "    train_X = add_one(train_X) \n",
    "    test_X = add_one(test_X)\n",
    "    \n",
    "    train_Y = create_one_hot(train_Y, num_class)\n",
    "\n",
    "    # Create NN classifier\n",
    "    # Bạn có thể biến đổi thêm/bớt hidden layer, thay đổi hàm activation cho mỗi layer\n",
    "    # và quan sát sự khác biệt trong quá trình train.\n",
    "    net = NeuralNetwork(learning_rate=LEARNING_RATE, num_class=num_class, reg=REG)\n",
    "    net.add_layer(100, 'relu')\n",
    "    net.add_layer(100, 'relu')\n",
    "    net.add_layer(100, 'relu')\n",
    "    net.add_layer(num_class, 'softmax')\n",
    "\n",
    "    if use_batch_train:\n",
    "        #Batch training - train all dataset\n",
    "        batch_train(train_X, train_Y, EPOCHS, net, bat=True)\n",
    "    else:\n",
    "        #Minibatch training - training dataset using Minibatch approach\n",
    "        minibatch_train(train_X, train_Y, EPOCHS, BATCH_SIZE, num_class, net)\n",
    "    metrics = confusion_matrix(test_Y, net.predict(test_X))\n",
    "    print(\"Confusion metrix: \")\n",
    "    print(metrics)\n",
    "    \n",
    "    print(\"Accuracy: \")\n",
    "    print(metrics.trace()/test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TexzWSA134rp"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "colab_type": "code",
    "id": "q-pC5wwi36nK",
    "outputId": "6506018f-c1ad-4f25-9d39-4f9314c04f3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bat_classification(use_batch_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou2UARc_4-WQ"
   },
   "source": [
    "### MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEtTnNI15S3-"
   },
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVIWAF_85W3d"
   },
   "outputs": [],
   "source": [
    "# Thay đổi giá trị của các hyperparameter bên dưới và\n",
    "# quan sát sự thay đổi của loss và quá trình training\n",
    "EPOCHS = 300\n",
    "LEARNING_RATE = 0.01\n",
    "REG= 1e-5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnBkMY4M5afF"
   },
   "source": [
    "#### Định nghĩa hàm `mnist_classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFxeQSW9WU6p"
   },
   "outputs": [],
   "source": [
    "def mnist_classification(use_batch_train=True):\n",
    "    # Load data from file\n",
    "    # Make sure that fashion-mnist/*.gz is in data/\n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = get_mnist_data(1)\n",
    "    train_X, val_X, test_X = normalize(train_X, val_X, test_X)    \n",
    "    \n",
    "    num_class = (np.unique(train_Y)).shape[0]\n",
    "\n",
    "    # Pad 1 as the third feature of train_x and test_x\n",
    "    train_X = add_one(train_X)\n",
    "    val_X = add_one(val_X)\n",
    "    test_X = add_one(test_X)\n",
    "    \n",
    "    train_Y = create_one_hot(train_Y, num_class)\n",
    "    val_Y = create_one_hot(val_Y, num_class)\n",
    "\n",
    "    # Create NN classifier\n",
    "    net = NeuralNetwork(learning_rate=LEARNING_RATE, num_class=num_class, reg=REG)\n",
    "    net.add_layer(128, 'relu')\n",
    "    net.add_layer(256, 'relu')\n",
    "    net.add_layer(100, 'relu')\n",
    "    net.add_layer(64, 'relu')\n",
    "    net.add_layer(num_class, 'softmax')\n",
    "     \n",
    "    if use_batch_train:\n",
    "        #Batch training - train all dataset\n",
    "        batch_train(train_X, train_Y, EPOCHS, net)\n",
    "    else:\n",
    "        #Minibatch training - training dataset using Minibatch approach\n",
    "        minibatch_train(train_X, train_Y, EPOCHS, BATCH_SIZE, num_class, net)\n",
    "    metrics = confusion_matrix(test_Y, net.predict(test_X))\n",
    "    print(\"Confusion metrix: \")\n",
    "    print(metrics)\n",
    "\n",
    "    print(\"Accuracy: \")\n",
    "    print(metrics.trace()/test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "xbVkCOajWU6t",
    "outputId": "1eaa6df5-0781-4bf9-8edf-e2e26d36b1da"
   },
   "outputs": [],
   "source": [
    "mnist_classification(use_batch_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENZ_priJWU6v"
   },
   "source": [
    "### II/Thực hiện Deep Neural Network với Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhQk2HiCwQjt"
   },
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45er7c5AWU6v"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "L = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DtdFOdFWU6x"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8yYS3SJzwVP-"
   },
   "source": [
    "### Cài đặt class `DNNModel`\n",
    "\n",
    "Trong phần này bạn có các TODO sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viMp39N6wYxi"
   },
   "source": [
    "#### \\[TODO 10] Cài đặt kiến trúc mô hình\n",
    "\n",
    "Yêu cầu: xây dựng kiến trúc mạng với `tf.keras.Sequential()` để chồng các hidden layers và output layer với nhau. (1đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SswRaNBUwcez"
   },
   "source": [
    "#### [TODO 11] Cài đặt hàm tính accuracy\n",
    "\n",
    "Cài đặt hàm tính accuracy. (1đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AuWz1knwfxQ"
   },
   "source": [
    "#### \\[TODO 12\\] Cài đặt hàm train\n",
    "Cài đặt các bước để train mô hình trong class `DNNModel`. (2đ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOrRAyEiWU6y"
   },
   "outputs": [],
   "source": [
    "class DNNModel:\n",
    "    def __init__(self, hidden_layers, num_classes, activation, epochs, optimizer):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        #Hidden layers and output layers are stacked to form a model\n",
    "        self.model = tf.keras.Sequential()\n",
    "        #### [TODO 10] START CODE HERE ####\n",
    "        for num_nodes in self.hidden_layers: #Add hidden layers\n",
    "            self.model.add(L.Dense(units=num_nodes, activation=self.activation))\n",
    "        self.model.add(L.Dense(units=self.num_classes, activation=tf.nn.softmax)) #Add output layer\n",
    "        #### END CODE HERE ####\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Compute loss function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_hat: output of the last layer (softmax layer).\n",
    "        y: labels/targets in our data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Loss w.r.t y_hat and y. Should be a scalar.\n",
    "        \"\"\"\n",
    "        return tf.reduce_mean(-tf.reduce_sum(y*tf.math.log(y_hat), axis=1), axis=0)\n",
    "\n",
    "    def accuracy(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Compute accuracy score.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_hat: output of the last layer (softmax layer).\n",
    "        y: labels/targets in our data.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Accuracy w.r.t y_hat and y. Should be a scalar.\n",
    "        \n",
    "        \"\"\"\n",
    "        #### [TODO 11] START CODE HERE ####\n",
    "        correct_result = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct_result, tf.float32))\n",
    "            \n",
    "        #### END CODE HERE ####\n",
    "        return acc\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        all_loss = []\n",
    "        all_acc = []\n",
    "        for e in range(self.epochs):\n",
    "            #### [TODO 12] START CODE HERE ####\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_hat = self.model(x_train)\n",
    "                loss = self.loss(y_hat, y_train)\n",
    "                accuracy = self.accuracy(y_hat, y_train)\n",
    "            \n",
    "            variables = self.model.variables\n",
    "            \n",
    "            gradients = tape.gradient(loss, variables)\n",
    "\n",
    "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "            \n",
    "            all_loss.append(loss)\n",
    "            \n",
    "            all_acc.append(accuracy)\n",
    "            \n",
    "            #### END CODE HERE ####\n",
    "            \n",
    "            print(f\"\\rEpoch: {e}... Training loss: {loss}... Accuracy: {accuracy}\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        Y_hat = self.model(inputs)\n",
    "        return tf.argmax(Y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vw1e7NV6w_H8"
   },
   "source": [
    "### Bat classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oX6kx8LRWU62"
   },
   "outputs": [],
   "source": [
    "def tf_bat_classification():\n",
    "     # Load data from file\n",
    "    # Make sure that bat.dat is in data/\n",
    "    train_X, train_Y, test_X, test_Y = get_bat_data()\n",
    "    train_X, _, test_X = normalize(train_X, train_X, test_X)    \n",
    "\n",
    "    test_Y  = test_Y.flatten()\n",
    "    train_Y = train_Y.flatten()\n",
    "    num_class = (np.unique(train_Y)).shape[0]\n",
    "\n",
    "    # Pad 1 as the third feature of train_x and test_x\n",
    "    train_X = add_one(train_X) \n",
    "    test_X = add_one(test_X)\n",
    "    \n",
    "    train_Y = create_one_hot(train_Y, num_class)\n",
    "    \n",
    "    # DNN parameters\n",
    "    hidden_layers = [100, 100, 100]\n",
    "    learning_rate = 0.001\n",
    "    epochs = 200\n",
    "    activation = tf.nn.relu\n",
    "    # optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "\n",
    "    #Initialize model\n",
    "    dnn = DNNModel(hidden_layers=hidden_layers, num_classes=num_class,\n",
    "                   activation=activation, epochs=epochs, optimizer=optimizer)\n",
    "    #Train\n",
    "    dnn.train(train_X, train_Y)\n",
    "\n",
    "    # TEST\n",
    "    # Confusion matrix\n",
    "    metrics = confusion_matrix(test_Y, dnn.predict(test_X))\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics)\n",
    "    \n",
    "    print(\"Accuracy: \")\n",
    "    print(metrics.trace()/test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XIDdnQ3SWU65",
    "outputId": "b69e73ac-5006-4dea-a2e2-33572a2ca839"
   },
   "outputs": [],
   "source": [
    "tf_bat_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zs6IMFGYxC8H"
   },
   "source": [
    "### MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBYDUF49WU67"
   },
   "outputs": [],
   "source": [
    "def tf_mnist_classification():\n",
    "    # Load data from file\n",
    "    # Make sure that fashion-mnist/*.gz is in data/\n",
    "    train_X, train_Y, val_X, val_Y, test_X, test_Y = get_mnist_data(1)\n",
    "    train_X, val_X, test_X = normalize(train_X, val_X, test_X)    \n",
    "    \n",
    "    num_class = (np.unique(train_Y)).shape[0]\n",
    "\n",
    "    # Pad 1 as the third feature of train_x and test_x\n",
    "    train_X = add_one(train_X)\n",
    "    val_X = add_one(val_X)\n",
    "    test_X = add_one(test_X)\n",
    "    \n",
    "    train_Y = create_one_hot(train_Y, num_class)\n",
    "    val_Y = create_one_hot(val_Y, num_class)\n",
    "\n",
    "    # Define hyper-parameters and train-related parameters\n",
    "    hidden_layers = [128, 256, 100, 64]\n",
    "    learning_rate = 0.01\n",
    "    epochs = 100\n",
    "    activation = tf.nn.relu\n",
    "    # optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "\n",
    "    #Initialize model\n",
    "    dnn = DNNModel(hidden_layers=hidden_layers, num_classes=num_class,\n",
    "                   activation=activation, epochs=epochs, optimizer=optimizer)\n",
    "    #Train\n",
    "    dnn.train(train_X, train_Y)\n",
    "\n",
    "    # TEST\n",
    "    # Confusion matrix\n",
    "    metrics = confusion_matrix(test_Y, dnn.predict(test_X))\n",
    "    print('Confusion matrix:')\n",
    "    print(metrics)\n",
    "    print(\"Accuracy: \")\n",
    "    print(metrics.trace()/test_Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Qv1dUpGLWU68",
    "outputId": "775a5c61-37c3-4181-c4bc-22ab4ea40167"
   },
   "outputs": [],
   "source": [
    "tf_mnist_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "leXWHS7Y1P63"
   },
   "source": [
    "## III. Thang điểm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbE0byhD1Tab"
   },
   "source": [
    "| TODO  | Điểm  |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "|\\[TODO 1\\] Cài đặt các hàm activation   |  1 |   |   |   |\n",
    "|\\[TODO 2\\] Hàm `forward`/`HiddenLayer` | 1  |   |   |   |\n",
    "|\\[TODO 3\\] Hàm `backward`/`HiddenLayer`  | 2  |   |   |   |\n",
    "|\\[TODO 4\\] Hàm `forward`/`NeuralNetwork`  | 0.5  |   |   |   |\n",
    "|\\[TODO 5\\] Hàm `compute_loss`/`NeuralNetwork`  | 1.5  |   |   |   |\n",
    "|\\[TODO 6\\] Hàm `compute_delta_grad_last`/`NeuralNetwork`  | 1  |   |   |   |\n",
    "|\\[TODO 7\\] Hàm `backward`/`NeuralNetwork`  | 1  |   |   |   |\n",
    "|\\[TODO 8\\] Hàm `update_weight_momentum`/`NeuralNetwork`  | 1  |   |   |   |\n",
    "|\\[TODO 9\\] Hàm `minibatch_train`  | 2  |   |   |   |\n",
    "|\\[TODO 10\\] Cài đặt kiến trúc Neural network sử dụng tensorflow  | 1  |   |   |   |\n",
    "|\\[TODO 11\\] Cài đặt hàm tính accuracy  | 1  |   |   |   |\n",
    "|\\[TODO 12\\] Cài đặt hàm train trong class `DNNModel`  | 2  |   |   |   |\n",
    "|**Tổng**| **15**  |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZhNMhztBiQk"
   },
   "source": [
    "## Author: Giang Tran, Hoa Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PK7QqUOyBvBL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2.SolutionDeepNeuralNetwork.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
